{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DL Challenge\n",
    "\n",
    "Team:\n",
    "German Novykov\n",
    "Alexiy Pidnebesnyi\n",
    "Mark Vaykul\n",
    "\n",
    "3 models, training our model from scratch, fine tuning, using tensorflow and pre trained models, as well as pytorch with google vit from Huggingface.\n",
    "\n",
    "\n",
    "2st model fine tuning pre trained model ResNet\n",
    "\n",
    "3st model Google vit. by far the strongest one but can recognise everything already"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83d3c15e27195f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1st model, trained solely on data provided in the challenge. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c95e39d9596628b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9af71d1a364d56ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data with tensorflow method XXX"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c17b2276bc16c4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Set the parameters for your data\n",
    "batch_size = 32\n",
    "image_size = (224,224)\n",
    "validation_split = 0.2\n",
    "\n",
    "# Create the training dataset from the 'train' directory\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory='./train/train',\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    validation_split=validation_split,\n",
    "    subset='training',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Create the validation dataset from the 'train' directory\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    directory='./train/train',\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    directory='./test',\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "print(train_ds)\n",
    "for images, labels in train_ds.take(1):  # 'take(1)' takes just one batch from the dataset\n",
    "    print(\"Shape of training images:\", images.shape)  # Prints the shape of images\n",
    "    print(\"Shape of training labels:\", labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1de8be7508af94c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
